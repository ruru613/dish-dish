import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from fastai.vision.all import *
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
import base64
import random
import matplotlib.pyplot as plt
import time
import shutil
import torch
import pickle
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="é£Ÿå ‚èœå“è¯†åˆ«ç³»ç»Ÿ", layout="wide")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'user_ratings' not in st.session_state:
    st.session_state.user_ratings = []
if 'user_id' not in st.session_state:
    st.session_state.user_id = int(time.time() * 1000) % 1000000
if 'current_page' not in st.session_state:
    st.session_state.current_page = "é¦–é¡µ"
if 'collab_model' not in st.session_state:
    st.session_state.collab_model = None

# æ–‡ä»¶è·¯å¾„é…ç½®
RATINGS_FILE = Path(__file__).parent / 'è¯„åˆ†æ•°æ®.xlsx'
BACKUP_DIR = Path(__file__).parent / 'ratings_backups'
DISHES_FILE = Path(__file__).parent / "èœå“ä»‹ç».xlsx"
MODEL_PATH = Path(__file__).parent / "dish.pkl"  # æ¨¡å‹è·¯å¾„

# åˆ›å»ºå¤‡ä»½ç›®å½•
BACKUP_DIR.mkdir(exist_ok=True)

# å®‰å…¨åŠ è½½æ¨¡å‹ï¼ˆä¿®å¤è·¯å¾„å’Œpickleé—®é¢˜ï¼‰
def load_model():
    if not MODEL_PATH.exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
    
    logger.info(f"å¼€å§‹åŠ è½½æ¨¡å‹: {MODEL_PATH}")
    
    try:
        # æ–¹æ¡ˆ1ï¼šä½¿ç”¨ Learner.load æ›¿ä»£ load_learnerï¼ˆæ›´å®‰å…¨ï¼‰
        # æ³¨æ„ï¼šéœ€è¦é‡æ–°åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„DataLoaders
        data = ImageDataLoaders.from_folder(
            path=Path(__file__).parent,  # å‡è®¾å›¾ç‰‡åœ¨å½“å‰ç›®å½•
            valid_pct=0.2,
            item_tfms=Resize(224),
            batch_tfms=aug_transforms(),
            bs=32
        )
        learn = vision_learner(data, resnet34, metrics=error_rate)
        learn.load(str(MODEL_PATH.with_suffix('')))  # åŠ è½½æƒé‡
        logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ (æ–¹æ³•1)")
        return learn
        
    except Exception as e1:
        logger.warning(f"æ–¹æ³•1åŠ è½½å¤±è´¥: {e1}. å°è¯•æ–¹æ³•2...")
        try:
            # æ–¹æ¡ˆ2ï¼šä½¿ç”¨ torch.loadï¼ˆæ›´åº•å±‚ï¼‰
            with open(MODEL_PATH, 'rb') as f:
                model = torch.load(f, map_location='cpu', pickle_module=pickle)
            logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ (æ–¹æ³•2)")
            return model
        except Exception as e2:
            logger.error(f"æ–¹æ³•2åŠ è½½å¤±è´¥: {e2}. å°è¯•æ–¹æ³•3...")
            try:
                # æ–¹æ¡ˆ3ï¼šä½¿ç”¨ load_learner ä½†è½¬ä¸ºå­—ç¬¦ä¸²è·¯å¾„
                model = load_learner(str(MODEL_PATH))
                logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ (æ–¹æ³•3)")
                return model
            except Exception as e3:
                error_msg = f"æ¨¡å‹åŠ è½½å¤±è´¥:\næ–¹æ³•1é”™è¯¯: {e1}\næ–¹æ³•2é”™è¯¯: {e2}\næ–¹æ³•3é”™è¯¯: {e3}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)

# åŠ è½½æ¨¡å‹ï¼ˆä»…ä¸€æ¬¡ï¼‰
try:
    model = load_model()
except Exception as e:
    st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    st.stop()

# åŠ è½½èœå“ä¿¡æ¯
try:
    dishes_df = pd.read_excel(DISHES_FILE)
    
    # æ„å»ºèœå“IDæ˜ å°„
    dish_names = model.dls.vocab
    dish_id_map = {}
    for idx, row in dishes_df.iterrows():
        dish_name = row['dish_name']
        if dish_name in dish_names:
            dish_id_map[dish_name] = row.get('dish_id', idx + 1)
    
    # éªŒè¯æ˜ å°„å®Œæ•´æ€§
    missing_dishes = [d for d in dish_names if d not in dish_id_map]
    if missing_dishes:
        st.warning(f"è­¦å‘Š: èœå“ä¿¡æ¯è¡¨ä¸­ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹ç±»åˆ«: {', '.join(missing_dishes)}")
        logger.warning(f"èœå“ä¿¡æ¯è¡¨ä¸­ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹ç±»åˆ«: {', '.join(missing_dishes)}")
        
except Exception as e:
    st.error(f"èœå“ä¿¡æ¯åŠ è½½å¤±è´¥: {e}")
    logger.error(f"èœå“ä¿¡æ¯åŠ è½½å¤±è´¥: {e}")
    st.stop()

# è¾…åŠ©å‡½æ•°
def predict_dish(image):
    """ä½¿ç”¨æ¨¡å‹é¢„æµ‹èœå“"""
    try:
        img = PILImage.create(image)
        pred, pred_idx, probs = model.predict(img)
        
        if pred not in dish_names:
            st.warning(f"å¼‚å¸¸é¢„æµ‹ç»“æœ: {pred} ä¸åœ¨æ¨¡å‹ç±»åˆ«åˆ—è¡¨ä¸­")
            logger.warning(f"å¼‚å¸¸é¢„æµ‹ç»“æœ: {pred} ä¸åœ¨æ¨¡å‹ç±»åˆ«åˆ—è¡¨ä¸­")
            pred = dish_names[np.argmax(probs)]
            st.info(f"å·²è‡ªåŠ¨æ›´æ­£ä¸ºæœ€å¯èƒ½ç±»åˆ«: {pred}")
            logger.info(f"å·²è‡ªåŠ¨æ›´æ­£ä¸ºæœ€å¯èƒ½ç±»åˆ«: {pred}")
            
        return pred, probs[pred_idx].item(), probs
    except Exception as e:
        st.error(f"é¢„æµ‹å¤±è´¥: {e}")
        logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
        return None, 0, None

def display_dish_info(dish_name):
    """è·å–èœå“è¯¦ç»†ä¿¡æ¯"""
    if dish_name not in dish_id_map:
        return {
            "åç§°": dish_name,
            "èœç³»": "æœªçŸ¥",
            "å£å‘³": "æœªçŸ¥",
            "å¡è·¯é‡Œ": "æœªçŸ¥",
            "æè¿°": "æš‚æ— è¯¦ç»†ä¿¡æ¯",
            "æ¨èäººç¾¤": "æœªçŸ¥",
            "ç¦å¿Œäººç¾¤": "æœªçŸ¥",
            "image": None
        }
        
    dish_info = dishes_df[dishes_df['dish_name'] == dish_name].iloc[0]
    return {
        "åç§°": dish_name,
        "èœç³»": dish_info['cuisine'],
        "å£å‘³": dish_info['taste'],
        "å¡è·¯é‡Œ": f"{dish_info['calorie']}å¤§å¡æ¯100å…‹",
        "æè¿°": dish_info['description'],
        "æ¨èäººç¾¤": dish_info['recommended population'],
        "ç¦å¿Œäººç¾¤": dish_info['contraindicated population'],
        "image": dish_info.get('image', None)
    }

def set_page_style():
    """è®¾ç½®é¡µé¢æ ·å¼"""
    st.markdown("""
    <style>
    .centered-title {
        text-align: center;
        font-size: 36px;
        font-weight: bold;
        color: #FF6B6B;
        margin: 20px 0;
    }
    .card {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    .rating-stars {
        color: #FFD700;
        font-size: 24px;
    }
    .recommendation-card {
        border-left: 4px solid #FF6B6B;
        padding-left: 15px;
        margin-bottom: 15px;
    }
    .highlight {
        color: #FF6B6B;
        font-weight: bold;
    }
    .error-message {
        color: red;
        font-weight: bold;
    }
    .sidebar-title {
        font-size: 20px;
        font-weight: bold;
        color: #FF6B6B;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)

def get_download_link(df, filename):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    try:
        csv = df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">ä¸‹è½½è¯„åˆ†æ•°æ®</a>'
        return href
    except Exception as e:
        st.warning(f"ç”Ÿæˆä¸‹è½½é“¾æ¥å¤±è´¥: {e}")
        return None

def backup_ratings():
    """å¤‡ä»½è¯„åˆ†æ•°æ®"""
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        backup_path = f"{BACKUP_DIR}/ratings_{timestamp}.xlsx"
        if RATINGS_FILE.exists():
            shutil.copy2(RATINGS_FILE, backup_path)
            logger.info(f"è¯„åˆ†æ•°æ®å¤‡ä»½æˆåŠŸ: {backup_path}")
            return backup_path
        return None
    except Exception as e:
        st.warning(f"è¯„åˆ†æ•°æ®å¤‡ä»½å¤±è´¥: {e}")
        logger.error(f"è¯„åˆ†æ•°æ®å¤‡ä»½å¤±è´¥: {e}")
        return None

def load_all_ratings():
    """å®‰å…¨åŠ è½½è¯„åˆ†æ•°æ®"""
    try:
        if RATINGS_FILE.exists():
            return pd.read_excel(RATINGS_FILE)
        return pd.DataFrame(columns=['user_id', 'dish_id', 'rating', 'timestamp'])
    except Exception as e:
        st.warning(f"è¯„åˆ†æ•°æ®æ–‡ä»¶æŸåï¼Œå·²åˆ›å»ºç©ºæ•°æ®: {e}")
        logger.error(f"è¯„åˆ†æ•°æ®æ–‡ä»¶æŸå: {e}")
        return pd.DataFrame(columns=['user_id', 'dish_id', 'rating', 'timestamp'])

def save_rating_safely(user_id, dish_id, rating):
    """å®‰å…¨ä¿å­˜è¯„åˆ†æ•°æ®"""
    # æ–°å¢å¼‚å¸¸å€¼æ ¡éªŒ
    if not (1 <= rating <= 5):
        return False, "è¯„åˆ†éœ€åœ¨1-5æ˜ŸèŒƒå›´å†…,æ— æ³•ä¿å­˜"
    if dish_id not in dish_id_map.values():
        return False, "æ— æ•ˆçš„èœå“ID,æ— æ³•ä¿å­˜è¯„åˆ†"
    
    new_rating = pd.DataFrame({
        'user_id': [user_id],
        'dish_id': [dish_id],
        'rating': [rating],
        'timestamp': [pd.Timestamp.now()]
    })
    
    try:
        backup_path = backup_ratings()
        if backup_path:
            st.info(f"å·²åˆ›å»ºè¯„åˆ†æ•°æ®å¤‡ä»½: {backup_path}")
            
        existing_data = load_all_ratings()
        combined_data = pd.concat([existing_data, new_rating], ignore_index=True)
        combined_data = combined_data.sort_values('timestamp', ascending=False)
        combined_data = combined_data.drop_duplicates(subset=['user_id', 'dish_id'], keep='first')
        
        combined_data.to_excel(RATINGS_FILE, index=False)
        user_ratings = combined_data[combined_data['user_id'] == user_id].copy()
        st.session_state.user_ratings = user_ratings.to_dict('records')
        
        logger.info(f"ç”¨æˆ· {user_id} å¯¹èœå“ {dish_id} è¯„åˆ† {rating} ä¿å­˜æˆåŠŸ")
        return True, "è¯„åˆ†ä¿å­˜æˆåŠŸ"
    
    except Exception as e:
        logger.error(f"è¯„åˆ†ä¿å­˜å¤±è´¥: {e}")
        return False, f"è¯„åˆ†ä¿å­˜å¤±è´¥: {str(e)}"

def load_collaborative_filtering_model():
    """åŠ è½½ååŒè¿‡æ»¤æ¨¡å‹"""
    try:
        if Path(RATINGS_FILE).exists():
            data_df = load_all_ratings()
            
            if len(data_df) < 10:
                st.warning("è¯„åˆ†æ•°æ®ä¸è¶³ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨è")
                logger.info("è¯„åˆ†æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨åŸºç¡€æ¨è")
                return None
                
            reader = Reader(line_format='user item rating', rating_scale=(1, 5))
            data = Dataset.load_from_df(data_df[['user_id', 'dish_id', 'rating']], reader)
            trainset = data.build_full_trainset()
            
            algo = SVD(random_state=42, n_factors=100, n_epochs=5)
            algo.fit(trainset)
            logger.info("ååŒè¿‡æ»¤æ¨¡å‹åŠ è½½æˆåŠŸ")
            return algo
        else:
            st.warning("è¯„åˆ†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨è")
            logger.info("è¯„åˆ†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸºç¡€æ¨è")
            return None
    except Exception as e:
        st.warning(f"ååŒè¿‡æ»¤æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨è: {e}")
        logger.error(f"ååŒè¿‡æ»¤æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

# é¡µé¢å‡½æ•°
def home_page():
    """é¦–é¡µ"""
    st.markdown('<div class="centered-title">ğŸ± é£Ÿå ‚èœå“è¯†åˆ«ç³»ç»Ÿ</div>', unsafe_allow_html=True)
    
    st.markdown(f"""
    è¿™æ˜¯ä¸€ä¸ªåŸºäºååŒè¿‡æ»¤ç®—æ³•çš„é£Ÿå ‚èœå“è¯†åˆ«ä¸æ¨èç³»ç»Ÿã€‚æ‚¨å¯ä»¥ä¸Šä¼ èœå“å›¾ç‰‡ï¼Œç³»ç»Ÿå°†è¯†åˆ«èœå“å¹¶ä¸ºæ‚¨æä¾›èœå“è¯¦ç»†ä¿¡æ¯ï¼Œåœ¨æ‚¨é£Ÿç”¨è¿‡åå¯ä»¥å¯¹èœå“è¿›è¡Œè¯„åˆ†ï¼Œ
    è¯„åˆ†åç³»ç»Ÿä¼šæ ¹æ®æ‚¨çš„å£å‘³åå¥½ä¸ºæ‚¨æ¨èå…¶ä»–èœå“,ç¥æ‚¨ç”¨é¤æ„‰å¿«ğŸ½ï¸ğŸ½ï¸ğŸ½ï¸!       å½“å‰ç”¨æˆ·ID: <span class='highlight'>{st.session_state.user_id}</span>
    """, unsafe_allow_html=True)
    
    st.info("è¯·é€šè¿‡å·¦ä¾§å¯¼èˆªæ é€‰æ‹©åŠŸèƒ½æ¨¡å—")

def dish_recognition_page():
    """èœå“è¯†åˆ«é¡µé¢"""
    st.markdown('<div class="centered-title">ğŸ½ï¸ èœå“è¯†åˆ«</div>', unsafe_allow_html=True)
    
    st.subheader("ä¸Šä¼ èœå“å›¾ç‰‡")
    uploaded_file = st.file_uploader("é€‰æ‹©å›¾ç‰‡", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None:
        col1, col2 = st.columns([1, 1])
        with col1:
            st.image(uploaded_file, caption="ä¸Šä¼ çš„èœå“å›¾ç‰‡", use_container_width=True)
        
        with st.spinner("æ­£åœ¨è¯†åˆ«èœå“..."):
            try:
                img = PILImage.create(uploaded_file)
                if img.size[0] < 50 or img.size[1] < 50:
                    st.warning("å›¾ç‰‡å°ºå¯¸è¿‡å°ï¼Œå¯èƒ½å½±å“è¯†åˆ«å‡†ç¡®ç‡")
                    logger.warning("å›¾ç‰‡å°ºå¯¸è¿‡å°")
                    
                pred_dish, confidence, probs = predict_dish(img)
                if pred_dish:
                    st.markdown(f"è¯†åˆ«ç»“æœ: <span class='highlight'>{pred_dish}</span> (ç½®ä¿¡åº¦: {confidence*100:.2f}%)", unsafe_allow_html=True)
                    
                    st.subheader("èœå“ä»‹ç»")
                    dish_info = display_dish_info(pred_dish)
                    for key, value in dish_info.items():
                        if key != "image":
                            st.markdown(f"**{key}:** {value}")
                    
                    st.subheader("è¯†åˆ«æ¦‚ç‡åˆ†å¸ƒ")
                    valid_dishes = [dish for dish in dish_names if dish in dishes_df['dish_name'].values]
                    filtered_probs = [probs[i] for i, dish in enumerate(dish_names) if dish in valid_dishes]
                    
                    top5 = sorted(zip(valid_dishes, filtered_probs), key=lambda x: x[1], reverse=True)[:5]
                    labels = [item[0] for item in top5]
                    values = [item[1] for item in top5]
                    
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.bar(labels, values, color='tomato')
                    ax.set_ylabel('æ¦‚ç‡')
                    ax.set_title('èœå“è¯†åˆ«æ¦‚ç‡åˆ†å¸ƒ')
                    ax.tick_params(axis='x', rotation=45)
                    st.pyplot(fig)
                    
                    # è¯„åˆ†åŠŸèƒ½
                    st.subheader("è¯„ä»·è¯¥èœå“")
                    rating = st.slider("è¯·ç»™å‡ºè¯„åˆ† (1-5æ˜Ÿ)", 1, 5, 3)
                    
                    if st.button("æäº¤è¯„åˆ†"):
                        dish_id = dish_id_map.get(pred_dish, 0)
                        if dish_id == 0:
                            st.error(f"æœªæ‰¾åˆ°èœå“ {pred_dish} çš„IDæ˜ å°„,è¯„åˆ†å¤±è´¥")
                            logger.error(f"æœªæ‰¾åˆ°èœå“ {pred_dish} çš„IDæ˜ å°„")
                            return
                            
                        success, message = save_rating_safely(
                            user_id=st.session_state.user_id,
                            dish_id=dish_id,
                            rating=rating
                        )
                        
                        if success:
                            st.success(f"æ„Ÿè°¢è¯„åˆ†ï¼æ‚¨ç»™{pred_dish}æ‰“äº†{rating}æ˜Ÿ")
                            st.markdown(f"<div class='rating-stars'>{'â­' * rating}</div>", unsafe_allow_html=True)
                            logger.info(f"ç”¨æˆ· {st.session_state.user_id} ç»™ {pred_dish} è¯„åˆ† {rating}")
                            
                            # é‡æ–°åŠ è½½ååŒè¿‡æ»¤æ¨¡å‹
                            st.session_state['collab_model'] = load_collaborative_filtering_model()
                            
                            # æä¾›ä¸‹è½½é“¾æ¥
                            if st.session_state.user_ratings:
                                ratings_df = pd.DataFrame(st.session_state.user_ratings)
                                download_link = get_download_link(ratings_df, f'user_{st.session_state.user_id}_ratings.csv')
                                if download_link:
                                    st.markdown(download_link, unsafe_allow_html=True)
                        else:
                            st.error(message)
                            logger.error(f"è¯„åˆ†æäº¤å¤±è´¥: {message}")

            except Exception as e:
                st.error(f"å›¾ç‰‡å¤„ç†å‡ºé”™: {e}")
                logger.error(f"å›¾ç‰‡å¤„ç†å‡ºé”™: {e}")

def recommendation_page():
    """æ¨èé¡µé¢"""
    st.markdown('<div class="centered-title">ğŸ“‹ èœå“æ¨è</div>', unsafe_allow_html=True)
    
    if not st.session_state.user_ratings or len(st.session_state.user_ratings) == 0:
        st.warning("æ‚¨è¿˜æ²¡æœ‰è¯„åˆ†è®°å½•ï¼Œè¯·å…ˆè¯†åˆ«å¹¶è¯„ä»·èœå“ï¼Œä»¥ä¾¿è·å–ä¸ªæ€§åŒ–æ¨è")
        return
    
    st.subheader("ä¸ºæ‚¨æ¨èèœå“")
    with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨è..."):
        try:
            current_algo = st.session_state.get('collab_model', load_collaborative_filtering_model())
            
            if not current_algo:
                st.info("è¯„åˆ†æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨åŸºç¡€æ¨è")
                logger.info("ä½¿ç”¨åŸºç¡€æ¨è")
                rated_dish_ids = [r['dish_id'] for r in st.session_state.user_ratings]
                recommended_dishes = dishes_df[~dishes_df['dish_id'].isin(rated_dish_ids)].sample(3)
                
                st.success("ä¸ºæ‚¨æ¨èï¼ˆåŸºç¡€æ¨èï¼‰ï¼š")
                for i, row in recommended_dishes.iterrows():
                    with st.container():
                        st.markdown(f"""
                        <div class="recommendation-card">
                            <h4>**{i+1}. {row['dish_name']}** ({row['cuisine']})</h4>
                            <p>å£å‘³ï¼š{row['taste']} | å¡è·¯é‡Œï¼š{row['calorie']}å¤§å¡</p>
                            <p>æè¿°ï¼š{row['description']}</p>
                        </div>
                        """, unsafe_allow_html=True)
            else:
                new_user_ratings = pd.DataFrame(st.session_state.user_ratings)
                all_dish_ids = dishes_df['dish_id'].tolist()
                rated_dish_ids = new_user_ratings['dish_id'].tolist()
                unrated_dish_ids = [d for d in all_dish_ids if d not in rated_dish_ids]
                
                predictions = []
                for dish_id in unrated_dish_ids:
                    if dish_id in dishes_df['dish_id'].values:
                        pred = current_algo.predict(uid=st.session_state.user_id, iid=dish_id)
                        predictions.append((dish_id, pred.est))
                
                if predictions:
                    predictions_df = pd.DataFrame(predictions, columns=['dish_id', 'predicted_rating'])
                    recommendations = pd.merge(
                        predictions_df,
                        dishes_df[['dish_id', 'dish_name', 'cuisine', 'taste', 'calorie', 'description']],
                        on='dish_id'
                    ).sort_values('predicted_rating', ascending=False)
                    
                    st.success("ä¸ºæ‚¨æ¨èï¼ˆååŒè¿‡æ»¤ï¼‰ï¼š")
                    for i, row in recommendations.head(3).iterrows():
                        with st.container():
                            st.markdown(f"""
                            <div class="recommendation-card">
                                <h4>**{i+1}. {row['dish_name']}** ({row['cuisine']})</h4>
                                <p>é¢„æµ‹è¯„åˆ†ï¼š{row['predicted_rating']:.2f}æ˜Ÿ | å£å‘³ï¼š{row['taste']} | å¡è·¯é‡Œï¼š{row['calorie']}å¤§å¡</p>
                                <p>æè¿°ï¼š{row['description']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.warning("æ²¡æœ‰å¯æ¨èçš„èœå“ï¼Œè¯·å°è¯•è¯„ä»·æ›´å¤šèœå“")
                    logger.info("æ²¡æœ‰å¯æ¨èçš„èœå“")
                    
        except Exception as e:
            st.error(f"æ¨èç”Ÿæˆå¤±è´¥: {e}")
            logger.error(f"æ¨èç”Ÿæˆå¤±è´¥: {e}")

def rating_statistics_page():
    """è¯„åˆ†ç»Ÿè®¡é¡µé¢"""
    st.markdown('<div class="centered-title">ğŸ“Š è¯„åˆ†ç»Ÿè®¡</div>', unsafe_allow_html=True)
    
    if not st.session_state.user_ratings or len(st.session_state.user_ratings) == 0:
        st.warning("æ‚¨è¿˜æ²¡æœ‰è¯„åˆ†è®°å½•")
        return
    
    ratings_df = pd.DataFrame(st.session_state.user_ratings)
    
    st.subheader("è¯„åˆ†åˆ†å¸ƒ")
    rating_counts = ratings_df['rating'].value_counts().sort_index()
    st.bar_chart(rating_counts)
    
    st.subheader("æ‚¨æœ€å–œæ¬¢çš„èœå“")
    if 'dish_id' in ratings_df.columns and 'dish_name' in dishes_df.columns:
        most_liked = ratings_df.groupby('dish_id')['rating'].mean().nlargest(3)
        for dish_id, score in most_liked.items():
            try:
                dish_name = dishes_df[dishes_df['dish_id'] == dish_id]['dish_name'].iloc[0]
                st.markdown(f"- {dish_name}: {score:.2f}æ˜Ÿ")
            except:
                st.markdown(f"- æœªçŸ¥èœå“ (ID: {dish_id}): {score:.2f}æ˜Ÿ")

def test_page():
    """æµ‹è¯•é¡µé¢"""
    st.markdown('<div class="centered-title">ğŸ§ª ç³»ç»Ÿæµ‹è¯•</div>', unsafe_allow_html=True)
    
    st.subheader("æ¨¡å‹æµ‹è¯•")
    
    test_image = st.file_uploader("ä¸Šä¼ æµ‹è¯•å›¾ç‰‡", type=["jpg", "png", "jpeg"])
    
    if test_image:
        with st.spinner("æ­£åœ¨æµ‹è¯•æ¨¡å‹..."):
            try:
                img = PILImage.create(test_image)
                pred, confidence, probs = predict_dish(img)
                
                if pred:
                    st.markdown(f"**é¢„æµ‹ç»“æœ**: {pred} (ç½®ä¿¡åº¦: {confidence*100:.2f}%)")
                    
                    # æ˜¾ç¤ºå‰5ä¸ªé¢„æµ‹ç»“æœ
                    st.subheader("Top 5 é¢„æµ‹")
                    top5 = sorted(zip(dish_names, probs), key=lambda x: x[1], reverse=True)[:5]
                    for i, (dish, prob) in enumerate(top5):
                        st.markdown(f"{i+1}. {dish}: {prob*100:.2f}%")
                    
                    # æ˜¾ç¤ºå›¾ç‰‡
                    st.image(img, caption="æµ‹è¯•å›¾ç‰‡", use_container_width=True)
                    
                else:
                    st.error("æ¨¡å‹é¢„æµ‹å¤±è´¥")
                    
            except Exception as e:
                st.error(f"æµ‹è¯•å¤±è´¥: {e}")
                logger.error(f"æµ‹è¯•å¤±è´¥: {e}")

# ä¸»ç¨‹åº
def main():
    try:
        set_page_style()
        
        # ä¾§è¾¹æ å¯¼èˆª
        st.sidebar.markdown('<div class="sidebar-title">å¯¼èˆªèœå•</div>', unsafe_allow_html=True)
        page_options = ["é¦–é¡µ", "èœå“è¯†åˆ«", "èœå“æ¨è", "è¯„åˆ†ç»Ÿè®¡", "ç³»ç»Ÿæµ‹è¯•"]
        selected_page = st.sidebar.radio("é€‰æ‹©é¡µé¢", page_options)
        
        # æ›´æ–°å½“å‰é¡µé¢çŠ¶æ€
        st.session_state.current_page = selected_page
        
        # æ˜¾ç¤ºå¯¹åº”é¡µé¢
        if selected_page == "é¦–é¡µ":
            home_page()
        elif selected_page == "èœå“è¯†åˆ«":
            dish_recognition_page()
        elif selected_page == "èœå“æ¨è":
            recommendation_page()
        elif selected_page == "è¯„åˆ†ç»Ÿè®¡":
            rating_statistics_page()
        elif selected_page == "ç³»ç»Ÿæµ‹è¯•":
            test_page()
        
        # é¡µè„š
        st.markdown("---")
        st.write("é£Ÿå ‚èœå“è¯†åˆ«ç³»ç»Ÿ ğŸ½ï¸ | ç‰ˆæœ¬ 1.0.0")
        
    except Exception as e:
        st.error(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
        logger.critical(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}", exc_info=True)

if __name__ == "__main__":
    main()